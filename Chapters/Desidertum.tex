\begin{Desideratum}{Clustering Desideratum}

The essential considerations for the clustering approach (regardless of the input type) are as follows:
\begin{enumerate}
    \item \textbf{Relevance:} The clustering method should  highlight the inherent and semantically meaningful structures in the data.
    \item \textbf{Scalability:} The method should be able to scale with the dimensionality and volume of the input data.
    \item \textbf{Robustness:} The clustering should be resistant to noise and perturbations. Small changes in the input should not result in drastically different clustering results.
    \item \textbf{Interpretability:} Results from the clustering should be easily understandable and interpretable.
    \item \textbf{Compactness and Separation:} Compactness requires cohesive clusters, where all items in the cluster should be close to each other in the chosen representation space. Whereas, separation ensures inter-cluster distinctions, where different clusters should be as far apart from each other as possible.
    \item \textbf{Efficiency:} The cluster derivation method should be timely and efficient, as real-time analysis is often desired.
    \item \textbf{Consistency:} The method should allow for reproducibility in results. Meaning, the same input, when clustered multiple times under the same conditions, should yield the same results.
    
\end{enumerate}  
\end{Desideratum}



\begin{Desideratum}

    The essential considerations for the value assigned to a complex input feature are as follows:
\begin{enumerate}
    \item \textbf{Faithfulness:} The value should be indicating the combined importance of the input features that comprise the complex feature with respect to the network and the output.
    \item \textbf{Consistency:} The method should allow for reproducibility of results. Meaning, the same complex input feature, when evaluated on the same input and the same neural network, should yield the same results.
    \item \textbf{Granularity:} It's essential to maintain an appropriate level of detail that acknowledges the diversity and significance of complex features. 
    \item \textbf{Interdependence Awareness:} The methodology should recognise and address the relationships between features. It should account for both highly correlated and uncorrelated features and prevent overemphasis, underrepresentation, or dilution of individual feature's importance.
    \item \textbf{Robustness to Network Architecture:} As networks can vary significantly in terms of their depth, type of layers, and operations (e.g., pooling, batch normalisation, convolution, attention), the method should be robust enough to provide accurate importance values across different architectures.
    \item \textbf{Bias and Distortion Mitigation:} The method should minimise the introduction of biases or distortions. This requires careful consideration of outliers, extreme values, and the size of the complex input feature (\ie the number of elements that comprise it)
    \item \textbf{Transparency:} The process of assigning a singular importance value to complex input features should be transparent and easily interpretable as to how the value was derived.
    \item \textbf{Scalability:} The method should be scalable in order to handle vast numbers of complex features or large number of layers comprising the neural network, without sacrificing accuracy or interpretability.

\end{enumerate}  


% Chapter~\ref{chap:framework} outlines a set of desiderata for the clustering an importance value assignment. In this subsection the methods proposed in Chapter~\ref{chap:clustering}, Chapter~\ref{chapter:revLRP} and Chapter~\ref{chapter:REVEAL} are discussed in light of those consideration. 


In Chapter~\ref{chap:framework}, we outlined a set of essential desiderata for clustering methods, including relevance, scalability, robustness, interpretability, compactness and separation, efficiency, and consistency. The clustering approach presented in Chapter~\ref{chap:clustering} introduces a method for identifying input features in images, uniquely combining heatmap clustering with object identification. This integration allows for the selection of the most relevant features as determined by a relevance attribution algorithm, ensuring that the clusters formed are both \emph{relevant} and \emph{interpretable}. The proposed method also exhibits \emph{robustness}, though further testing is required to assess its full capacity to withstand noise. In terms of \emph{scalability}, various parameters for point distance in the DBSCAN algorithm are explored until achieving a desired cluster size and outlier ratio. This process is \emph{efficient}: clustering 4857 points with seven distance parameters on a Quad-Core Intel Core i5 processor takes only 46 seconds. However, incorporating the SAM method for entire image analysis slightly increases processing time. For example, processing 299$\times$299 images (as required by InceptionV3) takes approximately 178.802 seconds (or 2.98 minutes), while 224$\times$224 images (for models like VGG16, VGG19, ResNet50, and DenseNet121) take about 100.351 seconds (or 1.67 minutes). A noteworthy advancement is FastSAM~\cite{}, which promises a 52-fold speed increase over the current implementation, though its integration remains a task for future work. Notably, the method \emph{scales} linearly with the number of input features, often exceeding 50,176 for most networks, yet still retains relative \emph{efficiency} for practical applications. \emph{Compactness and separation} is achieved through DBSCAN's criteria for cluster formation, where a minimum number of points must be within a specified distance (epsilon) from a point to be considered part of a cluster. This criterion ensures dense, compact clusters, with non-conforming points treated as noise or outliers, thereby maintaining clear data separation. Lastly, the proposed clustering method is deterministic, ensuring \emph{consistency} by producing the same results when run multiple times on the same input.


The method through which a importance value is assigned to a complex input feature has a different set of essential desiderata as defined in Chapter~\ref{chap:framework}, including \emph{faithfulness}, \emph{consistency}, \emph{granularity}, \emph{interdependence awareness}, \emph{robustness to network architecture}, \emph{bias and distortion mitigation}, \emph{transparency} and \emph{scalability}. The first method proposed for assigning a single value of importance is through reverse relevance distribution tracing, where the method reverses the function of the underlying relevance distribution method. The rules proposed in Chapter~\ref{rev_LRP} are reversing \LRP~\cite{bach2015pixel}. As \LRP does conform to crucial fidelity criteria such as input invarance, sensitivity and saturation problem~\cite{} the reverse relevance distribution tracing does assign a \emph{faithful} single value of relevance indicating the combined importance of the input features that comprise the complex feature with respect to the network and the output. Both the \LRP\ and the  reverse relevance distribution tracing method use deterministic rules to assign relevance to neurons making the method \emph{consistant} and allowing for reproducibility of results. Key thing to note is that due to the limited amount of information passed through the network small errors may occur. Such errors may lead to come inconsistencies, but this can easily be dealt with using some form of quantisation. The reverse relevance distribution tracing method reverses \LRP's relevance layer by layer, this provides a level of \emph{granularity}, where the importance of a complex feature can be examined not only for the output classification, but also for any neuron or layer is of interest. The proposed method exhibits \emph{robustness} to network architecture, as it simply takes a Jacobian matrix to evaluate the relevance distributed from each neuron in one layer to each neuron in the preceding layer. This does not need any form of adaptation to new architectures. \emph{Bias and distortion mitigation} has not been considered for this approach and requires further investigation as to how outliers, extreme values, and the size of the complex input feature effect the relevance distributed to a complex input feature. The rules used for importance value assigned are clear and provide \emph{transparency} and easily interpretability as to how the value was derived. Despite the method exhibiting the majority of the desiderata outlined in Chapter~\ref{chap:framework}, the method suffers for serious \emph{scalability issues}. This method demands a significant amount of memory and processing power due to its reliance on computing Jacobian matrices. This computation is both memory-intensive and time-consuming, posing a barrier to its application in larger, more complex networks and applications where an explanation of the fly is needed. How this limitation can be overcome is a large future work discussion topic~\ref{dis:jac}.


The \CTC\ method proposed in Chapter~\ref{chapter:REVEAL} provides a much more computationally efficient and \emph{scalable} technique for assigning a single relevance score to a complex input feature. It only requires a forward pass through the network, where the functions at each layer are modified to mimic the behaviour of each layerâ€™s function during the forward pass given the entire input. The faithfulness of the method is tested by the sensitivity and input invariance of the method. Both of these qualities were assessed by introducing noise to the input and observing the resultant variations in the explanations provided. An ideal interpretability method should exhibit low sensitivity to minor noise perturbations, thereby demonstrating input invariance, particularly under the assumption of a robust network. Conversely, a substantial introduction of noise should lead to a noticeable
change in explanation. The results show that not only is the \CTC\ method \emph{faithful}, but that it observes a higher degree of input invariance than any other method in the literature, while still maintaining sensitivity. The rules to propagate relevance at each layer are deterministic and therefore the \CTC\ method allows for easy reproducibility and \emph{consistency}. Further the relevance is again distributed layer by layer allowing the contribution of a complex feature to be examined not only for the output classification, but also for any neuron or layer is of interest. There has been a particular focus in making the \CTC method \emph{interdependence aware}, were specific rules are defined (see Section~\ref{sec:scale}) to deal with the scaling of learned parameters, so that no overemphasis, underrepresentation, or dilution of individual feature's importance is introduced through the propagation of contributions. The method is \emph{robust to network architecture} and results can be seen for the most used CNNs in Chapter~\ref{chapter:results}. For other types of architectures new rules that allow for the propagation of relevance need to be defined, which is discussed in future work Section~\ref{futurectc}. Similar to the reverse relevance distribution tracing method, \emph{bias and distortion mitigation} has not been considered for this approach and requires further investigation as to how different properties of the complex input feature such as its size effect the relevance distributed. Finally, the method through which the rules distribute relevance are clearly defined and provide a \emph{transparent} way for assigning a contribution value to a complex input feature.
